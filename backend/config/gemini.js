import { GoogleGenerativeAI } from '@google/generative-ai';
import * as dotenv from 'dotenv';

dotenv.config();

// Initialize Google Generative AI with API key
const API_KEY = process.env.GEMINI_API_KEY;

if (!API_KEY) {
  console.warn('GEMINI_API_KEY not found in environment variables. AI validation will be disabled.');
}

const genAI = API_KEY ? new GoogleGenerativeAI(API_KEY) : null;

/**
 * Validates evidence using Gemini AI to detect AI-generated content
 * @param {Object} evidence - The evidence object to validate
 * @returns {Promise<Object>} - Validation results
 */
export const validateEvidence = async (evidence) => {
  if (!genAI) {
    console.warn('Gemini AI not initialized. Skipping evidence validation.');
    return {
      isVerified: false,
      verificationNotes: 'AI validation not available',
      confidenceScore: 0,
      isFlagged: false
    };
  }

  try {
    // Select the model
    const model = genAI.getGenerativeModel({ model: 'gemini-pro' });
    
    // Prepare the content to analyze based on evidence type
    let contentToAnalyze = '';
    
    if (evidence.evidenceType === 'testimonial') {
      contentToAnalyze = evidence.testimonialContent;
    } else if (evidence.description) {
      contentToAnalyze = evidence.description;
    } else {
      return {
        isVerified: false,
        verificationNotes: 'Not enough textual content to verify',
        confidenceScore: 0,
        isFlagged: false
      };
    }
    
    // Skip if content is too short
    if (contentToAnalyze.length < 50) {
      return {
        isVerified: false,
        verificationNotes: 'Content is too short for reliable verification',
        confidenceScore: 0,
        isFlagged: false
      };
    }

    // Create the prompt for AI analysis
    const prompt = `
      Please analyze the following content and determine if it appears to be AI-generated.
      Provide your assessment in JSON format with these fields:
      1. isAIGenerated (boolean): your determination if the content was likely generated by AI
      2. confidenceScore (number 0-1): how confident you are in this assessment
      3. reasoning (string): brief explanation of your reasoning
      4. contentType (string): the type of content you believe this is (personal account, factual reporting, creative writing, etc.)
      
      Content to analyze:
      "${contentToAnalyze}"
    `;

    // Generate content
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    // Extract JSON from the response (handle potential formatting issues)
    let jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Could not parse JSON from AI response');
    }
    
    // Parse the JSON response
    const analysis = JSON.parse(jsonMatch[0]);
    
    // Return formatted verification results
    return {
      isVerified: !analysis.isAIGenerated,
      verificationNotes: analysis.reasoning,
      confidenceScore: analysis.confidenceScore,
      contentType: analysis.contentType,
      isFlagged: analysis.isAIGenerated && analysis.confidenceScore > 0.7
    };
  } catch (error) {
    console.error('Error validating evidence with AI:', error);
    return {
      isVerified: false,
      verificationNotes: 'Error during AI validation: ' + error.message,
      confidenceScore: 0,
      isFlagged: false
    };
  }
};

/**
 * Process evidence through AI validation and update the database record
 */
export const processEvidenceValidation = async (evidenceId, Campaign, CampaignEvidence) => {
  try {
    // Fetch the evidence record
    const evidence = await CampaignEvidence.findById(evidenceId);
    
    if (!evidence) {
      console.error(`Evidence ID ${evidenceId} not found`);
      return;
    }
    
    // Perform AI validation
    const validationResults = await validateEvidence(evidence);
    
    // Update the evidence record with validation results
    evidence.verification = {
      ...evidence.verification,
      isVerified: validationResults.isVerified,
      verificationMethod: 'technical_analysis',
      verificationDate: new Date(),
      verificationNotes: validationResults.verificationNotes,
      confidenceScore: validationResults.confidenceScore
    };
    
    // If evidence is flagged as potentially AI-generated, update status
    if (validationResults.isFlagged) {
      evidence.status = 'under_review';
      evidence.reviewNotes = 'Flagged by AI as potentially generated content. Requires human review.';
    } else if (validationResults.isVerified) {
      evidence.status = 'accepted';
    }
    
    // Save the updated evidence record
    await evidence.save();
    
    console.log(`Evidence ${evidenceId} validation completed. Verified: ${validationResults.isVerified}`);
    
    return validationResults;
  } catch (error) {
    console.error(`Error processing evidence validation for ${evidenceId}:`, error);
    throw error;
  }
};